{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7954139,"sourceType":"datasetVersion","datasetId":4678076}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<font size=\"1\">\nSupplementary code for \"Build a Large Language Model From Scratch\": <a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">https://www.manning.com/books/build-a-large-language-model-from-scratch</a> <br>\nCode repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n</font>","metadata":{}},{"cell_type":"markdown","source":"# Working with Text","metadata":{}},{"cell_type":"markdown","source":"Packages that are being used in this notebook:","metadata":{}},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:26:48.799584Z","iopub.execute_input":"2024-03-28T06:26:48.800035Z","iopub.status.idle":"2024-03-28T06:27:01.429177Z","shell.execute_reply.started":"2024-03-28T06:26:48.799996Z","shell.execute_reply":"2024-03-28T06:27:01.427680Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.6.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from importlib.metadata import version\n\nimport tiktoken\nimport torch\n\nprint(\"torch version:\", version(\"torch\"))\nprint(\"tiktoken version:\", version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.431592Z","iopub.execute_input":"2024-03-28T06:27:01.431997Z","iopub.status.idle":"2024-03-28T06:27:01.442401Z","shell.execute_reply.started":"2024-03-28T06:27:01.431958Z","shell.execute_reply":"2024-03-28T06:27:01.441288Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"torch version: 2.1.2+cpu\ntiktoken version: 0.6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This chapter covers data preparation and sampling to get input data \"ready\" for the LLM","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/01.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Understanding word embeddings","metadata":{}},{"cell_type":"markdown","source":"- No code in this section","metadata":{}},{"cell_type":"markdown","source":"- There are any forms of embeddings; we focus on text embeddings in this book","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/02.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- LLMs work embeddings in high-dimensional spaces (i.e., thousands of dimensions)\n- Since we can't visualize such high-dimensional spaces (we humans think in 1, 2, or 3 dimensions), the figure below illustrates a 2-dimensipnal embedding space","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/03.webp\" width=\"300px\">","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Tokenizing text","metadata":{}},{"cell_type":"markdown","source":"- In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/04.webp\" width=\"300px\">","metadata":{}},{"cell_type":"markdown","source":"- Load raw text we want to work with\n","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/verdict-nlp/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n    \nprint(\"Total number of characters:\", len(raw_text))\nprint(raw_text[:103])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.444363Z","iopub.execute_input":"2024-03-28T06:27:01.444779Z","iopub.status.idle":"2024-03-28T06:27:01.455251Z","shell.execute_reply.started":"2024-03-28T06:27:01.444741Z","shell.execute_reply":"2024-03-28T06:27:01.454119Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Total number of characters: 20479\nI HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no grea\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- The goal is to tokenize and embed this text for an LLM\n- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above\n- The following regular expression will split on whitespaces","metadata":{}},{"cell_type":"code","source":"import re\n\ntext = \"Hello, world. This, is a test.Acvx\"\nresult = re.split(r'(\\s)', text)\n\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.456745Z","iopub.execute_input":"2024-03-28T06:27:01.457129Z","iopub.status.idle":"2024-03-28T06:27:01.464038Z","shell.execute_reply.started":"2024-03-28T06:27:01.457099Z","shell.execute_reply":"2024-03-28T06:27:01.462855Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.Acvx']\n","output_type":"stream"}]},{"cell_type":"code","source":"import re \ntext=\"Hello, world. thIS is a shoukhin.Abc\"\ntext1 = \"Hello, world. Is this-- a test?\"\n\nr1=re.split(' ',text)\nr2=re.split(r'()\\s',text)\nprint(r2)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.467720Z","iopub.execute_input":"2024-03-28T06:27:01.468059Z","iopub.status.idle":"2024-03-28T06:27:01.476811Z","shell.execute_reply.started":"2024-03-28T06:27:01.468031Z","shell.execute_reply":"2024-03-28T06:27:01.475883Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"['Hello,', '', 'world.', '', 'thIS', '', 'is', '', 'a', '', 'shoukhin.Abc']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- We don't only want to split on whitespaces but also commas and periods, so let's modify the regular expression to do that as well","metadata":{}},{"cell_type":"code","source":"result = re.split(r'([,.]|\\s)', text)\n\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.478213Z","iopub.execute_input":"2024-03-28T06:27:01.478536Z","iopub.status.idle":"2024-03-28T06:27:01.485977Z","shell.execute_reply.started":"2024-03-28T06:27:01.478510Z","shell.execute_reply":"2024-03-28T06:27:01.484894Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"['Hello', ',', '', ' ', 'world', '.', '', ' ', 'thIS', ' ', 'is', ' ', 'a', ' ', 'shoukhin', '.', 'Abc']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- As we can see, this creates empty strings, let's remove them","metadata":{}},{"cell_type":"code","source":"# Strip whitespace from each item and then filter out any empty strings.\nresult = [item for item in result if item.strip()]\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.487460Z","iopub.execute_input":"2024-03-28T06:27:01.487879Z","iopub.status.idle":"2024-03-28T06:27:01.496183Z","shell.execute_reply.started":"2024-03-28T06:27:01.487816Z","shell.execute_reply":"2024-03-28T06:27:01.495108Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"['Hello', ',', 'world', '.', 'thIS', 'is', 'a', 'shoukhin', '.', 'Abc']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This looks pretty good, but let's also handle other types of punctuation, such as periods, question marks, and so on","metadata":{}},{"cell_type":"code","source":"text = \"Hello, world. Is this-- a test?\"\n\nresult = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\nprint(result)\nresult = [item.strip() for item in result if item.strip()] #space remove by strip() function\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:42:19.188533Z","iopub.execute_input":"2024-03-28T06:42:19.189177Z","iopub.status.idle":"2024-03-28T06:42:19.198935Z","shell.execute_reply.started":"2024-03-28T06:42:19.189127Z","shell.execute_reply":"2024-03-28T06:42:19.197140Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"['Hello', ',', '', ' ', 'world', '.', '', ' ', 'Is', ' ', 'this', '--', '', ' ', 'a', ' ', 'test', '?', '']\n['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This is pretty good, and we are now ready to apply this tokenization to the raw text","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/05.webp\" width=\"350px\">","metadata":{}},{"cell_type":"code","source":"preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text) #verdict dataset theke raw_text data nilam\npreprocessed = [item.strip() for item in preprocessed if item.strip()] #white space removed korlam\n\n# print(preprocessed)\nprint(preprocessed[:30])\nprint(\"\\n  Dataset er length : \", len(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:53:17.224454Z","iopub.execute_input":"2024-03-28T06:53:17.224913Z","iopub.status.idle":"2024-03-28T06:53:17.235512Z","shell.execute_reply.started":"2024-03-28T06:53:17.224879Z","shell.execute_reply":"2024-03-28T06:53:17.234099Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n\n  Dataset er length :  4649\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- Let's calculate the total number of tokens","metadata":{}},{"cell_type":"code","source":"print(len(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.522688Z","iopub.execute_input":"2024-03-28T06:27:01.523390Z","iopub.status.idle":"2024-03-28T06:27:01.533088Z","shell.execute_reply.started":"2024-03-28T06:27:01.523352Z","shell.execute_reply":"2024-03-28T06:27:01.532157Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"4649\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.3 Converting tokens into token IDs","metadata":{}},{"cell_type":"markdown","source":"- Next, we convert the text tokens into token IDs that we can process via embedding layers later","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/06.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- From these tokens, we can now build a vocabulary that consists of all the unique tokens","metadata":{}},{"cell_type":"code","source":"all_words = sorted(list(set(preprocessed)))\nprint(all_words)\nvocab_size = len(all_words)\n\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T07:03:29.634418Z","iopub.execute_input":"2024-03-28T07:03:29.635113Z","iopub.status.idle":"2024-03-28T07:03:29.641043Z","shell.execute_reply.started":"2024-03-28T07:03:29.635080Z","shell.execute_reply":"2024-03-28T07:03:29.640102Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Carlo;', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindle:', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon-dancers', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Rickham;', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'There:', 'They', 'This', 'Those', 'Though', 'Thwing', 'Thwings', 'To', 'Usually', 'Venetian', 'Victor', 'Was', 'We', 'Well', 'What', 'When', 'Why', 'Yes', 'You', '_', 'a', 'abdication', 'able', 'about', 'about;', 'above', 'abruptly', 'absolute', 'absorbed', 'absurdity', 'academic', 'accuse', 'accustomed', 'across', 'activity', 'add', 'added', 'admirers', 'adopted', 'adulation', 'advance', 'aesthetic', 'affect', 'afraid', 'after', 'afterward', 'again', 'ago', 'ah', 'air', 'alive', 'all', 'almost', 'alone', 'along', 'always', 'am', 'amazement', 'amid', 'among', 'amplest', 'amusing', 'an', 'and', 'another', 'answer', 'answered', 'any', 'anything', 'anywhere', 'apparent', 'apparently', 'appearance', 'appeared', 'appointed', 'are', 'arm', 'arm-chair', 'arm-chairs', 'arms', 'art', 'articles', 'artist', 'as', 'aside', 'asked', 'at', 'atmosphere', 'atom', 'attack', 'attention', 'attention;', 'attitude', 'audacities', 'away', 'awful', 'axioms', 'azaleas', 'back', 'background', 'balance', 'balancing', 'balustraded', 'basking', 'bath-rooms', 'be', 'beaming', 'bean-stalk', 'bear', 'beard', 'beauty', 'became', 'because', 'becoming', 'bed', 'been', 'before', 'began', 'begun', 'behind', 'being', 'believed', 'beneath', 'bespoke', 'better', 'better;', 'between', 'big', 'bits', 'bitterness', 'blocked', 'born', 'borne', 'boudoir', 'bravura', 'break', 'breaking', 'breathing', 'bric-a-brac', 'briefly', 'brings', 'bronzes', 'brought', 'brown', 'brush', 'bull', 'business', 'but', 'buying', 'by', 'called', 'came', 'can', 'canvas', 'canvases', 'cards', 'care', 'career', 'caught', 'central', 'chair', 'chap', 'characteristic', 'charming', 'cheap', 'check', 'cheeks', 'chest', 'chimney-piece', 'chucked', 'cigar', 'cigarette', 'cigars', 'circulation', 'circumstance', 'circus-clown', 'claimed', 'clasping', 'clear', 'cleverer', 'close', 'clue', 'coat', 'collapsed', 'colour', 'come', 'comfortable', 'coming', 'companion', 'compared', 'complex', 'confident', 'congesting', 'conjugal', 'constraint', 'consummate', 'contended', 'continued', 'corner', 'corrected', 'could', 'couldn', 'count', 'countenance', 'couple', 'course', 'covered', 'craft', 'cried', 'crossed', 'crowned', 'crumbled', 'cry', 'cured', 'curiosity', 'curious', 'current', 'curtains', 'd', 'dabble', 'damask', 'dark', 'dashed', 'day', 'days', 'dead', 'deadening', 'dear', 'deep', 'deerhound', 'degree', 'delicate', 'demand', 'denied', 'deploring', 'deprecating', 'deprecatingly', 'desire', 'destroyed', 'destruction', 'desultory', 'detail', 'diagnosis', 'did', 'didn', 'died', 'dim', 'dimmest', 'dingy', 'dining-room', 'disarming', 'discovery;', 'discrimination', 'discussion', 'disdain', 'disdained', 'disease', 'disguised', 'display', 'dissatisfied', 'distinguished', 'distract', 'divert', 'do', 'doesn', 'doing', 'domestic', 'don', 'done', 'donkey', 'down', 'dozen', 'dragged', 'drawing-room', 'drawing-rooms', 'drawn', 'dress-closets', 'drew', 'dropped', 'each', 'earth', 'ease', 'easel', 'easy', 'echoed', 'economy', 'effect', 'effects', 'efforts', 'egregious', 'eighteenth-century', 'elbow', 'elegant', 'else', 'embarrassed', 'enabled', 'end', 'endless', 'enjoy', 'enlightenment:', 'enough', 'ensuing', 'equally', 'equanimity', 'escape', 'established', 'etching', 'even', 'event', 'ever', 'everlasting', 'every', 'exasperated', 'except', 'excuse', 'excusing', 'existed', 'expected', 'exquisite', 'exquisitely', 'extenuation', 'exterminating', 'extracting', 'eye', 'eyebrows', 'eyes', 'eyes:', 'face', 'faces', 'fact', 'faded', 'failed', 'failure', 'fair', 'faith', 'false', 'familiar', 'famille-verte', 'fancy', 'fashionable', 'fate', 'feather', 'feet', 'fell', 'fellow', 'felt', 'few', 'fewer', 'finality', 'find', 'fingers', 'first', 'fit', 'fitting', 'five', 'flash', 'flashed', 'florid', 'flowers', 'fluently', 'flung', 'follow', 'followed', 'fond', 'footstep', 'for', 'forced', 'forcing', 'forehead', 'foreign', 'foreseen', 'forgive', 'forgotten', 'form', 'formed', 'forming', 'forward', 'fostered', 'found', 'foundations', 'fragment', 'fragments', 'frame', 'frames', 'frequently', 'friend', 'from', 'full', 'fullest', 'furiously', 'furrowed', 'garlanded', 'garlands', 'gave', 'genial', 'genius', 'gesture', 'get', 'getting', 'give', 'given', 'glad', 'glanced', 'glimpse', 'gloried', 'glory', 'go', 'going', 'gone', 'good', 'good-breeding', 'good-humoured', 'got', 'grace', 'gradually', 'gray', 'grayish', 'great', 'greatest', 'greatness', 'grew', 'groping', 'growing', 'had', 'hadn', 'hair', 'half', 'half-light', 'half-mechanically', 'hall', 'hand', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'hard', 'hardly', 'has', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'height', 'her', 'here', 'here;', 'hermit', 'herself', 'hesitations', 'hide', 'high', 'him', 'him:', 'himself', 'hint', 'his', 'history', 'holding', 'home', 'honour', 'hooded', 'hostess', 'hostess:', 'hot-house', 'hour', 'hours', 'house', 'how', 'hung', 'husband', 'idea', 'idle', 'idling', 'if', 'immediately', 'in', 'incense', 'indifferent;', 'inevitable', 'inevitably', 'inflexible', 'insensible', 'insignificant', 'instinctively', 'instructive', 'interesting', 'into', 'ironic', 'irony', 'irrelevance', 'irrevocable', 'is', 'it', 'it;', 'its', 'itself', 'jardiniere', 'jealousy', 'just', 'keep', 'kept', 'kind', 'knees', 'knew', 'know', 'know;', 'known', 'laid', 'lair', 'landing', 'language', 'last', 'late', 'later', 'latter', 'laugh', 'laugh:', 'laughed', 'lay', 'leading', 'lean', 'learned', 'least', 'leathery:', 'leave', 'led', 'left', 'leisure', 'lends', 'lent', 'let', 'lies', 'life', 'life-likeness', 'lift', 'lifted', 'light', 'lightly;', 'like', 'liked', 'line', 'lines', 'lingered', 'lips', 'lit', 'little', 'little:', 'live', 'll', 'loathing', 'long', 'longed', 'longer', 'look', 'looked', 'looking', 'lose', 'loss', 'lounging', 'lovely', 'lucky', 'lump', 'luncheon-table', 'luxury', 'lying', 'made', 'make', 'man', 'manage', 'managed', 'mantel-piece', 'marble', 'married', 'may', 'me', 'meant', 'mediocrity', 'medium', 'mentioned', 'mere', 'merely', 'met', 'might', 'mighty', 'millionaire', 'mine', 'mine:', 'minute', 'minutes', 'mirrors', 'modest', 'modesty', 'moment', 'money', 'monumental', 'mood', 'morbidly', 'more', 'most', 'mourn', 'mourned', 'moustache', 'moved', 'much', 'muddling;', 'multiplied', 'murmur', 'muscles', 'must', 'my', 'myself', 'mysterious', 'naive', 'near', 'nearly', 'negatived', 'nervous', 'nervousness;', 'neutral', 'never', 'next', 'no', 'none', 'not', 'note', 'nothing', 'now', 'nymphs', 'oak', 'obituary', 'object', 'objects', 'occurred', 'oddly', 'of', 'off', 'often', 'oh', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'or', 'other', 'our', 'ourselves', 'out', 'out:', 'outline', 'oval', 'over', 'own', 'packed', 'paid', 'paint', 'painted', 'painted;', 'painter', 'painting', 'painting;', 'pale', 'paled', 'palm-trees;', 'panel', 'panelling', 'pardonable', 'pardoned', 'part', 'passages', 'passing', 'past', 'pastels', 'pathos', 'patient', 'people', 'perceptible', 'perfect', 'persistence', 'persuasively', 'phrase', 'picture', 'pictures', 'pines', 'pink', 'place', 'placed', 'plain', 'platitudes', 'pleased', 'pockets', 'point', 'poised', 'poor', 'portrait', 'posing', 'possessed', 'poverty', 'predicted', 'preliminary', 'presenting', 'prestidigitation', 'pretty', 'previous', 'price', 'pride', 'pride:', 'princely', 'prism', 'problem', 'proclaiming', 'prodigious', 'profusion', 'protest', 'prove', 'public', 'purblind', 'purely', 'pushed', 'put', 'qualities', 'quality', 'queerly', 'question', 'question:', 'quickly', 'quietly', 'quite', 'quote', 'rain', 'raised', 'random', 'rather', 're', 'real', 'really', 'reared', 'reason', 'reassurance', 'recovering', 'recreated', 'reflected', 'reflection', 'regrets', 'relatively', 'remained', 'remember', 'reminded', 'repeating', 'represented', 'reproduction', 'resented', 'resolve', 'resources', 'rest', 'rich', 'rich;', 'ridiculous', 'robbed', 'romantic', 'room', 'rose', 'rs', 'rule', 'run', 's', 'said', 'said:', 'same', 'satisfaction', 'satisfaction:', 'savour', 'saw', 'say', 'say:', 'saying', 'says', 'scorn', 'scornful', 'secret', 'see', 'seemed', 'seen', 'self-confident', 'send', 'sensation', 'sensitive', 'sent', 'serious', 'set', 'sex', 'shade', 'shaking', 'shall', 'she', 'shirked', 'short', 'should', 'shoulder', 'shoulders', 'show', 'showed', 'showy', 'shrug', 'shrugged', 'sight', 'sign', 'silent;', 'silver', 'similar', 'simpleton', 'simplifications', 'simply', 'since', 'single', 'sitter', 'sitters', 'sketch', 'skill', 'slight', 'slightly', 'slowly:', 'small', 'smile', 'smiling', 'sneer', 'so', 'solace', 'some', 'somebody', 'something', 'spacious', 'spaniel', 'speaking-tubes', 'speculations;', 'spite', 'splash', 'square', 'stairs', 'stammer', 'stand', 'standing', 'started', 'stay', 'still', 'stocked', 'stood', 'stopped', 'stopping', 'straddling', 'straight', 'strain', 'straining', 'strange', 'straw', 'stream', 'stroke', 'strokes', 'strolled', 'strongest', 'strongly', 'struck', 'studio', 'stuff', 'subject', 'substantial', 'suburban', 'such', 'suddenly', 'suffered', 'sugar', 'suggested', 'sunburn', 'sunburnt', 'sunlit', 'superb', 'sure', 'surest', 'surface', 'surprise', 'surprised', 'surrounded', 'suspected', 'sweetly', 'sweetness', 'swelling', 'swept', 'swum', 't', 'table', 'take', 'taken', 'talking', 'tea', 'tears', 'technicalities', 'technique', 'tell', 'tells', 'tempting', 'terra-cotta', 'terrace', 'terraces', 'terribly', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thither', 'those', 'though', 'thought', 'thought:', 'three', 'threshold', 'threw', 'through', 'throwing', 'tie', 'till', 'time', 'timorously', 'tinge', 'tips', 'tired', 'to', 'told', 'tone', 'tones', 'too', 'took', 'tottering', 'touched', 'toward', 'trace', 'trade', 'transmute', 'traps', 'travelled', 'tribute', 'tributes', 'tricks', 'tried', 'trouser-presses', 'true', 'truth', 'turned', 'twenty', 'twenty-four', 'twice', 'twirling', 'unaccountable', 'uncertain', 'under', 'underlay', 'underneath', 'understand', 'unexpected', 'untouched', 'unusual', 'up', 'up-stream', 'up;', 'upon', 'upset', 'upstairs', 'us', 'used', 'usual', 'value', 'varnishing', 'vases', 've', 'veins', 'velveteen', 'very', 'villa', 'vindicated', 'virtuosity', 'vista', 'vocation', 'voice', 'wall', 'wander', 'want', 'wanted', 'wants', 'was', 'wasn', 'watched', 'watching', 'water-colour', 'waves', 'way', 'weekly', 'weeks', 'welcome', 'went', 'were', 'what', 'when', 'whenever', 'where', 'which', 'while', 'white', 'white-panelled', 'who', 'whole', 'whom', 'why', 'wide', 'widow', 'wife', 'wild', 'wincing', 'wincing;', 'window-curtains', 'wish', 'with', 'without', 'wits', 'woman', 'women', 'women:', 'won', 'wonder', 'wondered', 'word', 'work', 'working', 'worth', 'would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself']\n1159\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab = {token:integer for integer,token in enumerate(all_words)}","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.546598Z","iopub.execute_input":"2024-03-28T06:27:01.547039Z","iopub.status.idle":"2024-03-28T06:27:01.555305Z","shell.execute_reply.started":"2024-03-28T06:27:01.547010Z","shell.execute_reply":"2024-03-28T06:27:01.554258Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"- Below are the first 50 entries in this vocabulary:","metadata":{}},{"cell_type":"code","source":"for i, item in enumerate(vocab.items()):\n    print(item)\n    if i >= 50:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.556588Z","iopub.execute_input":"2024-03-28T06:27:01.557067Z","iopub.status.idle":"2024-03-28T06:27:01.567074Z","shell.execute_reply.started":"2024-03-28T06:27:01.557036Z","shell.execute_reply":"2024-03-28T06:27:01.565981Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"('!', 0)\n('\"', 1)\n(\"'\", 2)\n('(', 3)\n(')', 4)\n(',', 5)\n('--', 6)\n('.', 7)\n(':', 8)\n(';', 9)\n('?', 10)\n('A', 11)\n('Ah', 12)\n('Among', 13)\n('And', 14)\n('Are', 15)\n('Arrt', 16)\n('As', 17)\n('At', 18)\n('Be', 19)\n('Begin', 20)\n('Burlington', 21)\n('But', 22)\n('By', 23)\n('Carlo', 24)\n('Carlo;', 25)\n('Chicago', 26)\n('Claude', 27)\n('Come', 28)\n('Croft', 29)\n('Destroyed', 30)\n('Devonshire', 31)\n('Don', 32)\n('Dubarry', 33)\n('Emperors', 34)\n('Florence', 35)\n('For', 36)\n('Gallery', 37)\n('Gideon', 38)\n('Gisburn', 39)\n('Gisburns', 40)\n('Grafton', 41)\n('Greek', 42)\n('Grindle', 43)\n('Grindle:', 44)\n('Grindles', 45)\n('HAD', 46)\n('Had', 47)\n('Hang', 48)\n('Has', 49)\n('He', 50)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- Below, we illustrate the tokenization of a short sample text using a small vocabulary:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/07.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- Putting it now all together into a tokenizer class","metadata":{}},{"cell_type":"code","source":"class SimpleTokenizerV1:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.572110Z","iopub.execute_input":"2024-03-28T06:27:01.572646Z","iopub.status.idle":"2024-03-28T06:27:01.581041Z","shell.execute_reply.started":"2024-03-28T06:27:01.572611Z","shell.execute_reply":"2024-03-28T06:27:01.579923Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- The `encode` function turns text into token IDs\n- The `decode` function turns token IDs back into text","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/08.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- We can use the tokenizer to encode (that is, tokenize) texts into integers\n- These integers can then be embedded (later) as input of/for the LLM","metadata":{}},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV1(vocab)\n\ntext = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\"\"\"\nids = tokenizer.encode(text)\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.582457Z","iopub.execute_input":"2024-03-28T06:27:01.582789Z","iopub.status.idle":"2024-03-28T06:27:01.592883Z","shell.execute_reply.started":"2024-03-28T06:27:01.582760Z","shell.execute_reply":"2024-03-28T06:27:01.591841Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"[1, 58, 2, 872, 1013, 615, 541, 763, 5, 1155, 608, 5, 1, 69, 7, 39, 873, 1136, 773, 812, 7]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- We can decode the integers back into text","metadata":{}},{"cell_type":"code","source":"tokenizer.decode(ids)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.594075Z","iopub.execute_input":"2024-03-28T06:27:01.595164Z","iopub.status.idle":"2024-03-28T06:27:01.604657Z","shell.execute_reply.started":"2024-03-28T06:27:01.595133Z","shell.execute_reply":"2024-03-28T06:27:01.603601Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode(text))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.606268Z","iopub.execute_input":"2024-03-28T06:27:01.606603Z","iopub.status.idle":"2024-03-28T06:27:01.615891Z","shell.execute_reply.started":"2024-03-28T06:27:01.606577Z","shell.execute_reply":"2024-03-28T06:27:01.614892Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2.4 Adding special context tokens","metadata":{}},{"cell_type":"markdown","source":"- It's useful to add some \"special\" tokens for unknown words and to denote the end of a text","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/09.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- Some tokenizers use special tokens to help the LLM with additional context\n- Some of these special tokens are\n  - `[BOS]` (beginning of sequence) marks the beginning of text\n  - `[EOS]` (end of sequence) marks where the text ends (this is usually used to concatenate multiple unrelated texts, e.g., two different Wikipedia articles or two different books, and so on)\n  - `[PAD]` (padding) if we train LLMs with a batch size greater than 1 (we may include multiple texts with different lengths; with the padding token we pad the shorter texts to the longest length so that all texts have an equal length)\n- `[UNK]` to represent works that are not included in the vocabulary\n\n- Note that GPT-2 does not need any of these tokens mentioned above but only uses an `<|endoftext|>` token to reduce complexity\n- The  `<|endoftext|>` is analogous to the `[EOS]` token mentioned above\n- GPT also uses the `<|endoftext|>` for padding (since we typically use a mask when training on batched inputs, we would not attend padded tokens anyways, so it does not matter what these tokens are)\n- GPT-2 does not use an `<UNK>` token for out-of-vocabulary words; instead, GPT-2 uses a byte-pair encoding (BPE) tokenizer, which breaks down words into subword units which we will discuss in a later section\n\n","metadata":{}},{"cell_type":"markdown","source":"- We use the `<|endoftext|>` tokens between two independent sources of text:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/10.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- Let's see what happens if we tokenize the following text:","metadata":{}},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV1(vocab)\n\ntext = \"Hello, do you like tea. Is this-- a test?\"\n\ntokenizer.encode(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.617228Z","iopub.execute_input":"2024-03-28T06:27:01.617577Z","iopub.status.idle":"2024-03-28T06:27:01.686412Z","shell.execute_reply.started":"2024-03-28T06:27:01.617549Z","shell.execute_reply":"2024-03-28T06:27:01.683087Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizerV1(vocab)\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea. Is this-- a test?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[32], line 9\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m      8\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m----> 9\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n","Cell \u001b[0;32mIn[32], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m      8\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m----> 9\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n","\u001b[0;31mKeyError\u001b[0m: 'Hello'"],"ename":"KeyError","evalue":"'Hello'","output_type":"error"}]},{"cell_type":"markdown","source":"- The above produces an error because the word \"Hello\" is not contained in the vocabulary\n- To deal with such cases, we can add special tokens like `\"<|unk|>\"` to the vocabulary to represent unknown words\n- Since we are already extending the vocabulary, let's add another token called `\"<|endoftext|>\"` which is used in GPT-2 training to denote the end of a text (and it's also used between concatenated text, like if our training datasets consists of multiple articles, books, etc.)","metadata":{}},{"cell_type":"code","source":"preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text)\npreprocessed = [item.strip() for item in preprocessed if item.strip()]\n\nall_tokens = sorted(list(set(preprocessed)))\nall_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n\nvocab = {token:integer for integer,token in enumerate(all_tokens)}","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.687368Z","iopub.status.idle":"2024-03-28T06:27:01.688130Z","shell.execute_reply.started":"2024-03-28T06:27:01.687924Z","shell.execute_reply":"2024-03-28T06:27:01.687944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(vocab.items())","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.689085Z","iopub.status.idle":"2024-03-28T06:27:01.689433Z","shell.execute_reply.started":"2024-03-28T06:27:01.689268Z","shell.execute_reply":"2024-03-28T06:27:01.689283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, item in enumerate(list(vocab.items())[-5:]):\n    print(item)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.691151Z","iopub.status.idle":"2024-03-28T06:27:01.691729Z","shell.execute_reply.started":"2024-03-28T06:27:01.691446Z","shell.execute_reply":"2024-03-28T06:27:01.691470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We also need to adjust the tokenizer accordingly so that it knows when and how to use the new `<unk>` token","metadata":{}},{"cell_type":"code","source":"class SimpleTokenizerV2:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = { i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n        preprocessed = [item if item in self.str_to_int \n                        else \"<|unk|>\" for item in preprocessed]\n\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.693295Z","iopub.status.idle":"2024-03-28T06:27:01.693817Z","shell.execute_reply.started":"2024-03-28T06:27:01.693547Z","shell.execute_reply":"2024-03-28T06:27:01.693569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try to tokenize text with the modified tokenizer:","metadata":{}},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV2(vocab)\n\ntext1 = \"Hello, do you like tea?\"\ntext2 = \"In the sunlit terraces of the palace.\"\n\ntext = \" <|endoftext|> \".join((text1, text2))\n\nprint(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.695078Z","iopub.status.idle":"2024-03-28T06:27:01.695580Z","shell.execute_reply.started":"2024-03-28T06:27:01.695317Z","shell.execute_reply":"2024-03-28T06:27:01.695339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.697155Z","iopub.status.idle":"2024-03-28T06:27:01.697697Z","shell.execute_reply.started":"2024-03-28T06:27:01.697397Z","shell.execute_reply":"2024-03-28T06:27:01.697418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode(text))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.699317Z","iopub.status.idle":"2024-03-28T06:27:01.699879Z","shell.execute_reply.started":"2024-03-28T06:27:01.699582Z","shell.execute_reply":"2024-03-28T06:27:01.699604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.5 BytePair encoding","metadata":{}},{"cell_type":"markdown","source":"- GPT-2 used BytePair encoding (BPE) as its tokenizer\n- it allows the model to break down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle out-of-vocabulary words\n- For instance, if GPT-2's vocabulary doesn't have the word \"unfamiliarword,\" it might tokenize it as [\"unfam\", \"iliar\", \"word\"] or some other subword breakdown, depending on its trained BPE merges\n- The original BPE tokenizer can be found here: [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)\n- In this chapter, we are using the BPE tokenizer from OpenAI's open-source [tiktoken](https://github.com/openai/tiktoken) library, which implements its core algorithms in Rust to improve computational performance\n- I created a notebook in the [./bytepair_encoder](../02_bonus_bytepair-encoder) that compares these two implementations side-by-side (tiktoken was about 5x faster on the sample text)","metadata":{}},{"cell_type":"code","source":"# pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.701205Z","iopub.status.idle":"2024-03-28T06:27:01.701703Z","shell.execute_reply.started":"2024-03-28T06:27:01.701442Z","shell.execute_reply":"2024-03-28T06:27:01.701465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import importlib\nimport tiktoken\n\nprint(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.703058Z","iopub.status.idle":"2024-03-28T06:27:01.703562Z","shell.execute_reply.started":"2024-03-28T06:27:01.703301Z","shell.execute_reply":"2024-03-28T06:27:01.703323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.705235Z","iopub.status.idle":"2024-03-28T06:27:01.706251Z","shell.execute_reply.started":"2024-03-28T06:27:01.706020Z","shell.execute_reply":"2024-03-28T06:27:01.706044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n\nintegers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n\nprint(integers)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.709563Z","iopub.status.idle":"2024-03-28T06:27:01.709975Z","shell.execute_reply.started":"2024-03-28T06:27:01.709758Z","shell.execute_reply":"2024-03-28T06:27:01.709775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strings = tokenizer.decode(integers)\n\nprint(strings)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.711077Z","iopub.status.idle":"2024-03-28T06:27:01.711474Z","shell.execute_reply.started":"2024-03-28T06:27:01.711291Z","shell.execute_reply":"2024-03-28T06:27:01.711307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- BPE tokenizers break down unknown words into subwords and individual characters:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/11.webp\" width=\"300px\">","metadata":{}},{"cell_type":"markdown","source":"## 2.6 Data sampling with a sliding window","metadata":{}},{"cell_type":"markdown","source":"- We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/12.webp\" width=\"400px\">","metadata":{}},{"cell_type":"code","source":"with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n\nenc_text = tokenizer.encode(raw_text)\nprint(len(enc_text))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.713595Z","iopub.status.idle":"2024-03-28T06:27:01.714042Z","shell.execute_reply.started":"2024-03-28T06:27:01.713790Z","shell.execute_reply":"2024-03-28T06:27:01.713806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- For each text chunk, we want the inputs and targets\n- Since we want the model to predict the next word, the targets are the inputs shifted by one position to the right","metadata":{}},{"cell_type":"code","source":"enc_sample = enc_text[50:]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.715464Z","iopub.status.idle":"2024-03-28T06:27:01.715869Z","shell.execute_reply.started":"2024-03-28T06:27:01.715657Z","shell.execute_reply":"2024-03-28T06:27:01.715674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_size = 4\n\nx = enc_sample[:context_size]\ny = enc_sample[1:context_size+1]\n\nprint(f\"x: {x}\")\nprint(f\"y:      {y}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.717050Z","iopub.status.idle":"2024-03-28T06:27:01.717409Z","shell.execute_reply.started":"2024-03-28T06:27:01.717234Z","shell.execute_reply":"2024-03-28T06:27:01.717250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- One by one, the prediction would look like as follows:","metadata":{}},{"cell_type":"code","source":"for i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(context, \"---->\", desired)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.719095Z","iopub.status.idle":"2024-03-28T06:27:01.719579Z","shell.execute_reply.started":"2024-03-28T06:27:01.719348Z","shell.execute_reply":"2024-03-28T06:27:01.719365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.721238Z","iopub.status.idle":"2024-03-28T06:27:01.721601Z","shell.execute_reply.started":"2024-03-28T06:27:01.721425Z","shell.execute_reply":"2024-03-28T06:27:01.721440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We will take care of the next-word prediction in a later chapter after we covered the attention mechanism\n- For now, we implement a simple data loader that iterates over the input dataset and returns the inputs and targets shifted by one","metadata":{}},{"cell_type":"markdown","source":"- Install and import PyTorch (see Appendix A for installation tips)","metadata":{}},{"cell_type":"code","source":"import torch\nprint(\"PyTorch version:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.724510Z","iopub.status.idle":"2024-03-28T06:27:01.725164Z","shell.execute_reply.started":"2024-03-28T06:27:01.724901Z","shell.execute_reply":"2024-03-28T06:27:01.724923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We use a sliding window approach where we slide the window one word at a time (this is also known as `stride=1`):\n\n<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/13.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- Create dataset and dataloader that extract chunks from the input text dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.tokenizer = tokenizer\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={'<|endoftext|>'})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.726531Z","iopub.status.idle":"2024-03-28T06:27:01.727032Z","shell.execute_reply.started":"2024-03-28T06:27:01.726765Z","shell.execute_reply":"2024-03-28T06:27:01.726786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True):\n\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.728502Z","iopub.status.idle":"2024-03-28T06:27:01.729021Z","shell.execute_reply.started":"2024-03-28T06:27:01.728748Z","shell.execute_reply":"2024-03-28T06:27:01.728769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Let's test the dataloader with a batch size of 1 for an LLM with a context size of 4:","metadata":{}},{"cell_type":"code","source":"with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.730629Z","iopub.status.idle":"2024-03-28T06:27:01.731134Z","shell.execute_reply.started":"2024-03-28T06:27:01.730882Z","shell.execute_reply":"2024-03-28T06:27:01.730904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n\ndata_iter = iter(dataloader)\nfirst_batch = next(data_iter)\nprint(first_batch)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.732554Z","iopub.status.idle":"2024-03-28T06:27:01.733061Z","shell.execute_reply.started":"2024-03-28T06:27:01.732791Z","shell.execute_reply":"2024-03-28T06:27:01.732811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_batch = next(data_iter)\nprint(second_batch)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.734396Z","iopub.status.idle":"2024-03-28T06:27:01.734901Z","shell.execute_reply.started":"2024-03-28T06:27:01.734636Z","shell.execute_reply":"2024-03-28T06:27:01.734656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- An example using stride equal to the context length (here: 4) as shown below:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/14.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- We can also create batched outputs\n- Note that we increase the stride here so that we don't have overlaps between the batches, since more overlap could lead to increased overfitting","metadata":{}},{"cell_type":"code","source":"dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)\nprint(\"Inputs:\\n\", inputs)\nprint(\"\\nTargets:\\n\", targets)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.736218Z","iopub.status.idle":"2024-03-28T06:27:01.736704Z","shell.execute_reply.started":"2024-03-28T06:27:01.736444Z","shell.execute_reply":"2024-03-28T06:27:01.736475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.7 Creating token embeddings","metadata":{}},{"cell_type":"markdown","source":"- The data is already almost ready for an LLM\n- But lastly let us embed the tokens in a continuous vector representation using an embedding layer\n- Usually, these embedding layers are part of the LLM itself and are updated (trained) during model training","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/15.webp\" width=\"400px\">","metadata":{}},{"cell_type":"markdown","source":"- Suppose we have the following four input examples with input ids 5, 1, 3, and 2 (after tokenization):","metadata":{}},{"cell_type":"code","source":"input_ids = torch.tensor([2, 3, 5, 1])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.737878Z","iopub.status.idle":"2024-03-28T06:27:01.738343Z","shell.execute_reply.started":"2024-03-28T06:27:01.738101Z","shell.execute_reply":"2024-03-28T06:27:01.738121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- For the sake of simplicity, suppose we have a small vocabulary of only 6 words and we want to create embeddings of size 3:","metadata":{}},{"cell_type":"code","source":"vocab_size = 6\noutput_dim = 3\n\ntorch.manual_seed(123)\nembedding_layer = torch.nn.Embedding(vocab_size, output_dim)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.739992Z","iopub.status.idle":"2024-03-28T06:27:01.740478Z","shell.execute_reply.started":"2024-03-28T06:27:01.740223Z","shell.execute_reply":"2024-03-28T06:27:01.740243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- This would result in a 6x3 weight matrix:","metadata":{}},{"cell_type":"code","source":"print(embedding_layer.weight)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.741862Z","iopub.status.idle":"2024-03-28T06:27:01.742405Z","shell.execute_reply.started":"2024-03-28T06:27:01.742107Z","shell.execute_reply":"2024-03-28T06:27:01.742136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- For those who are familiar with one-hot encoding, the embedding layer approach above is essentially just a more efficient way of implementing one-hot encoding followed by matrix multiplication in a fully-connected layer, which is described in the supplementary code in [./embedding_vs_matmul](../03_bonus_embedding-vs-matmul)\n- Because the embedding layer is just a more efficient implementation that is equivalent to the one-hot encoding and matrix-multiplication approach it can be seen as a neural network layer that can be optimized via backpropagation","metadata":{}},{"cell_type":"markdown","source":"- To convert a token with id 3 into a 3-dimensional vector, we do the following:","metadata":{}},{"cell_type":"code","source":"print(embedding_layer(torch.tensor([3])))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.744229Z","iopub.status.idle":"2024-03-28T06:27:01.744730Z","shell.execute_reply.started":"2024-03-28T06:27:01.744480Z","shell.execute_reply":"2024-03-28T06:27:01.744501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Note that the above is the 4th row in the `embedding_layer` weight matrix\n- To embed all four `input_ids` values above, we do","metadata":{}},{"cell_type":"code","source":"print(embedding_layer(input_ids))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.746242Z","iopub.status.idle":"2024-03-28T06:27:01.746736Z","shell.execute_reply.started":"2024-03-28T06:27:01.746486Z","shell.execute_reply":"2024-03-28T06:27:01.746506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"- An embedding layer is essentially a look-up operation:","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.748214Z","iopub.status.idle":"2024-03-28T06:27:01.748719Z","shell.execute_reply.started":"2024-03-28T06:27:01.748466Z","shell.execute_reply":"2024-03-28T06:27:01.748486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/16.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- **You may be interested in the bonus content comparing embedding layers with regular linear layers: [../02_bonus_efficient-multihead-attention](../02_bonus_efficient-multihead-attention)**","metadata":{}},{"cell_type":"markdown","source":"## 2.8 Encoding word positions","metadata":{}},{"cell_type":"markdown","source":"- Embedding layer convert IDs into identical vector representations regardless of where they are located in the input sequence:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/17.webp\" width=\"400px\">","metadata":{}},{"cell_type":"markdown","source":"- Positional embeddings are combined with the token embedding vector to form the input embeddings for a large language model:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/18.webp\" width=\"500px\">","metadata":{}},{"cell_type":"markdown","source":"- The BytePair encoder has a vocabulary size of 50,257:\n- Suppose we want to encode the input tokens into a 256-dimensional vector representation:","metadata":{}},{"cell_type":"code","source":"vocab_size = 50257\noutput_dim = 256\n\ntoken_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.750170Z","iopub.status.idle":"2024-03-28T06:27:01.750674Z","shell.execute_reply.started":"2024-03-28T06:27:01.750408Z","shell.execute_reply":"2024-03-28T06:27:01.750429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- If we sample data from the dataloader, we embed the tokens in each batch into a 256-dimensional vector\n- If we have a batch size of 8 with 4 tokens each, this results in a 8 x 4 x 256 tensor:","metadata":{}},{"cell_type":"code","source":"max_length = 4\ndataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.752207Z","iopub.status.idle":"2024-03-28T06:27:01.752701Z","shell.execute_reply.started":"2024-03-28T06:27:01.752442Z","shell.execute_reply":"2024-03-28T06:27:01.752472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Token IDs:\\n\", inputs)\nprint(\"\\nInputs shape:\\n\", inputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.754202Z","iopub.status.idle":"2024-03-28T06:27:01.754690Z","shell.execute_reply.started":"2024-03-28T06:27:01.754434Z","shell.execute_reply":"2024-03-28T06:27:01.754464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_embeddings = token_embedding_layer(inputs)\nprint(token_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.756122Z","iopub.status.idle":"2024-03-28T06:27:01.756603Z","shell.execute_reply.started":"2024-03-28T06:27:01.756350Z","shell.execute_reply":"2024-03-28T06:27:01.756370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- GPT-2 uses absolute position embeddings, so we just create another embedding layer:","metadata":{}},{"cell_type":"code","source":"block_size = max_length\npos_embedding_layer = torch.nn.Embedding(block_size, output_dim)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.758199Z","iopub.status.idle":"2024-03-28T06:27:01.758709Z","shell.execute_reply.started":"2024-03-28T06:27:01.758429Z","shell.execute_reply":"2024-03-28T06:27:01.758448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_embeddings = pos_embedding_layer(torch.arange(max_length))\nprint(pos_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.759847Z","iopub.status.idle":"2024-03-28T06:27:01.760334Z","shell.execute_reply.started":"2024-03-28T06:27:01.760085Z","shell.execute_reply":"2024-03-28T06:27:01.760105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- To create the input embeddings used in an LLM, we simply add the token and the positional embeddings:","metadata":{}},{"cell_type":"code","source":"input_embeddings = token_embeddings + pos_embeddings\nprint(input_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T06:27:01.761562Z","iopub.status.idle":"2024-03-28T06:27:01.762060Z","shell.execute_reply.started":"2024-03-28T06:27:01.761790Z","shell.execute_reply":"2024-03-28T06:27:01.761809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In the initial phase of the input processing workflow, the input text is segmented into separate tokens\n- Following this segmentation, these tokens are transformed into token IDs based on a predefined vocabulary:","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/19.webp\" width=\"400px\">","metadata":{}},{"cell_type":"markdown","source":"# Summary and takeaways","metadata":{}},{"cell_type":"markdown","source":"**See the [./dataloader.ipynb](./dataloader.ipynb) code notebook**, which is a concise version of the data loader that we implemented in this chapter and will need for training the GPT model in upcoming chapters.\n\n**See [./exercise-solutions.ipynb](./exercise-solutions.ipynb) for the exercise solutions.**","metadata":{}}]}